{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78160e9-8c79-498c-8882-b42e65fbc325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b05e79-053d-49c9-a60a-7afd55009a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- USER CONFIG (change paths) --------\n",
    "TRAIN_DIR = r\"C:\\Users\\racha\\Downloads\\caltech-101-img\\caltech-101-img\\train\"\n",
    "VAL_DIR   = r\"C:\\Users\\racha\\Downloads\\caltech-101-img\\caltech-101-img\\val\"\n",
    "IMG_SIZE  = (128, 128)\n",
    "BATCH     = 32\n",
    "EPOCHS_HEAD = 3\n",
    "EPOCHS_FINE = 1\n",
    "SAVE_NAME = \"fast_mobilenet_caltech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8ce8fc-8ff5-4845-8ee4-15c3448e3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity\n",
    "if not os.path.isdir(TRAIN_DIR): raise ValueError(\"TRAIN_DIR not found\")\n",
    "if not os.path.isdir(VAL_DIR): raise ValueError(\"VAL_DIR not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef674237-f5f3-4eda-a3c6-41df7d29da97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected classes: 102\n",
      "Example: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes']\n"
     ]
    }
   ],
   "source": [
    "# --- create the 'classes' list (IMPORTANT) ---\n",
    "classes = sorted([d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))])\n",
    "NUM_CLASSES = len(classes)\n",
    "print(\"Detected classes:\", NUM_CLASSES)\n",
    "print(\"Example:\", classes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d051a30-e752-4f23-a576-93e58a61416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7280 files belonging to 102 classes.\n",
      "Found 1864 files belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "# --- create datasets ---\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=classes,         # use same class order for both sets\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=classes,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2367605d-673d-495a-be0e-6efaf00c2932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# --- build small fast model (MobileNetV2 backbone) ---\n",
    "base = MobileNetV2(input_shape=(*IMG_SIZE,3), include_top=False, weights='imagenet')\n",
    "base.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(*IMG_SIZE,3))\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.compile(optimizer=optimizers.Adam(1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca572f13-c31d-4655-a757-d5729f4f7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "228/228 [==============================] - 224s 923ms/step - loss: 1.8325 - accuracy: 0.6120 - val_loss: 0.5679 - val_accuracy: 0.8632\n",
      "Epoch 2/3\n",
      "228/228 [==============================] - 204s 895ms/step - loss: 0.4915 - accuracy: 0.8727 - val_loss: 0.4294 - val_accuracy: 0.8841\n",
      "Epoch 3/3\n",
      "228/228 [==============================] - 216s 949ms/step - loss: 0.2804 - accuracy: 0.9240 - val_loss: 0.3880 - val_accuracy: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d40947ac0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- train classifier head (quick) ---\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_HEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3e067ca-f1d6-4a60-8f7f-c07f4aaff127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 243s 990ms/step - loss: 0.1808 - accuracy: 0.9544 - val_loss: 0.3741 - val_accuracy: 0.8981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d4246be80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- quick fine-tune: unfreeze last few layers ---\n",
    "for layer in base.layers[:-15]:\n",
    "    layer.trainable = False\n",
    "for layer in base.layers[-15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e581b-2eea-415f-9974-a07b262cca69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
